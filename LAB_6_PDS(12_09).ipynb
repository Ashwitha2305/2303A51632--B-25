{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNaRQkL1O1p8axF2Zqreymy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashwitha2305/2303A51632--B-25/blob/main/LAB_6_PDS(12_09).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIXfAynC14Mi",
        "outputId": "c41db352-9e56-4fa8-998a-b5e0002dabc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Hospital Dataset (with outliers):\n",
            "   patient_id  age\n",
            "0           1   25\n",
            "1           2   40\n",
            "2           3   -5\n",
            "3           4  130\n",
            "4           5   55\n",
            "5           6   70\n",
            "6           7  200\n",
            "7           8   15\n",
            "8           9   90\n",
            "9          10   45 \n",
            "\n",
            "Detected Outliers:\n",
            "   patient_id  age\n",
            "2           3   -5\n",
            "3           4  130\n",
            "6           7  200 \n",
            "\n",
            "Cleaned Hospital Dataset (outliers removed):\n",
            "   patient_id  age\n",
            "0           1   25\n",
            "1           2   40\n",
            "4           5   55\n",
            "5           6   70\n",
            "7           8   15\n",
            "8           9   90\n",
            "9          10   45 \n",
            "\n",
            "* Why Outlier Removal Matters:\n",
            "1.Outliers such as age < 0 or > 120 are unrealistic in hospital data.\n",
            "2.Keeping them skews analysis (e.g., average patient age).\n",
            "3.Cleaning ensures accurate statistics, better visualizations, and valid medical insights.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Create Hospital Dataset with Ages\n",
        "data = {\n",
        "    'patient_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    'age': [25, 40, -5, 130, 55, 70, 200, 15, 90, 45]  # includes invalid ages\n",
        "}\n",
        "hospital_df = pd.DataFrame(data)\n",
        "\n",
        "print(\"Original Hospital Dataset (with outliers):\")\n",
        "print(hospital_df, \"\\n\")\n",
        "\n",
        "# Step 2: Detect Outliers (invalid ages < 0 or > 120)\n",
        "\n",
        "outliers = hospital_df[(hospital_df['age'] < 0) | (hospital_df['age'] > 120)]\n",
        "print(\"Detected Outliers:\")\n",
        "print(outliers, \"\\n\")\n",
        "\n",
        "# Step 3: Remove Outliers\n",
        "\n",
        "cleaned_df = hospital_df[(hospital_df['age'] >= 0) & (hospital_df['age'] <= 120)]\n",
        "\n",
        "print(\"Cleaned Hospital Dataset (outliers removed):\")\n",
        "print(cleaned_df, \"\\n\")\n",
        "\n",
        "# Step 4: Discussion\n",
        "\n",
        "print(\"* Why Outlier Removal Matters:\")\n",
        "print(\"1.Outliers such as age < 0 or > 120 are unrealistic in hospital data.\")\n",
        "print(\"2.Keeping them skews analysis (e.g., average patient age).\")\n",
        "print(\"3.Cleaning ensures accurate statistics, better visualizations, and valid medical insights.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# Step 1: Create Banking Dataset with Incomes\n",
        "\n",
        "data = {\n",
        "    'customer_id': [1, 2, 3, 4, 5],\n",
        "    'income': [25000, 40000, 60000, 80000, 120000]  # incomes in INR\n",
        "}\n",
        "bank_df = pd.DataFrame(data)\n",
        "\n",
        "print(\"Original Banking Dataset:\")\n",
        "print(bank_df, \"\\n\")\n",
        "\n",
        "# Step 2: Min-Max Normalization (scales values between 0 and 1)\n",
        "\n",
        "scaler_minmax = MinMaxScaler()\n",
        "bank_df['income_minmax'] = scaler_minmax.fit_transform(bank_df[['income']])\n",
        "\n",
        "print(\"After Min-Max Normalization:\")\n",
        "print(bank_df[['customer_id', 'income', 'income_minmax']], \"\\n\")\n",
        "\n",
        "# Step 3: Standardization (Z-score scaling: mean=0, std=1)\n",
        "\n",
        "scaler_standard = StandardScaler()\n",
        "bank_df['income_standard'] = scaler_standard.fit_transform(bank_df[['income']])\n",
        "\n",
        "print(\"After Standardization (Z-score):\")\n",
        "print(bank_df[['customer_id', 'income', 'income_standard']], \"\\n\")\n",
        "\n",
        "# Step 4: Discussion\n",
        "print(\"* When to Use Scaling:\")\n",
        "print(\"1.Min-Max Normalization is useful when features need to be within a fixed range (e.g., 0 to 1), often in neural networks.\")\n",
        "print(\"2.Standardization is useful when features follow a normal distribution or when using algorithms sensitive to variance (e.g., Logistic Regression, SVM, K-Means).\")\n",
        "print(\"3.Scaling ensures fair contribution of features, avoids bias from large values, and speeds up convergence in ML models.\")\n"
      ],
      "metadata": {
        "id": "lZ0Ydoqi2jj-",
        "outputId": "ded264f3-649e-4bc7-a9a2-874883574c82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Banking Dataset:\n",
            "   customer_id  income\n",
            "0            1   25000\n",
            "1            2   40000\n",
            "2            3   60000\n",
            "3            4   80000\n",
            "4            5  120000 \n",
            "\n",
            "After Min-Max Normalization:\n",
            "   customer_id  income  income_minmax\n",
            "0            1   25000       0.000000\n",
            "1            2   40000       0.157895\n",
            "2            3   60000       0.368421\n",
            "3            4   80000       0.578947\n",
            "4            5  120000       1.000000 \n",
            "\n",
            "After Standardization (Z-score):\n",
            "   customer_id  income  income_standard\n",
            "0            1   25000        -1.206045\n",
            "1            2   40000        -0.753778\n",
            "2            3   60000        -0.150756\n",
            "3            4   80000         0.452267\n",
            "4            5  120000         1.658312 \n",
            "\n",
            "* When to Use Scaling:\n",
            "1.Min-Max Normalization is useful when features need to be within a fixed range (e.g., 0 to 1), often in neural networks.\n",
            "2.Standardization is useful when features follow a normal distribution or when using algorithms sensitive to variance (e.g., Logistic Regression, SVM, K-Means).\n",
            "3.Scaling ensures fair contribution of features, avoids bias from large values, and speeds up convergence in ML models.\n"
          ]
        }
      ]
    }
  ]
}